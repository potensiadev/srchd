# Phase 1 ê°œë°œ ìš”êµ¬ì‚¬í•­ ë° ì•„í‚¤í…ì²˜ ì„¤ê³„

> **Last Updated**: 2026-02-14
> **Version**: 1.0.0
> **Status**: ì„¤ê³„ ì™„ë£Œ, êµ¬í˜„ ëŒ€ê¸° (TIER 4 - í”¼ë“œë°± ê¸°ë°˜)

---

## 1. Executive Summary

### 1.1 í˜„ì¬ ìƒíƒœ

| êµ¬ë¶„ | ìƒíƒœ | ìƒì„¸ |
|------|------|------|
| **êµ¬í˜„ ì™„ë£Œ (6ê°œ)** | âœ… | RouterAgent, IdentityChecker, AnalystAgent, ValidationAgent, PrivacyAgent, VisualAgent |
| **Phase 1 ê³„íš (3ê°œ)** | ğŸ“‹ | DocumentClassifier, CoverageCalculator, GapFillerAgent |
| **í•„ë“œ ì™„ì„±ë„** | ~78% | ëª©í‘œ: 90%+ |
| **íŒŒì´í”„ë¼ì¸ ì§€ì—°** | 8-15ì´ˆ | ëª©í‘œ P95: <18ì´ˆ |

### 1.2 Phase 1 ëª©í‘œ

1. **í•„ë“œ ì™„ì„±ë„ í–¥ìƒ**: 78% â†’ 90%+ (`CoverageCalculator` + `GapFillerAgent`)
2. **ë¹„ì´ë ¥ì„œ í•„í„°ë§**: í¬ë ˆë”§ ë‚­ë¹„ ë°©ì§€ (`DocumentClassifier`)
3. **Unified Context ê°•í™”**: ëª¨ë“  ì—ì´ì „íŠ¸ê°€ `evidence_map` ê³µìœ 

### 1.3 êµ¬í˜„ ìš°ì„ ìˆœìœ„ (ë°±ë¡œê·¸ ê¸°ì¤€)

```
í˜„ì¬ ìœ„ì¹˜: TIER 4 (ë°ì´í„° ê¸°ë°˜ ê°œì„ )
íŠ¸ë¦¬ê±° ì¡°ê±´:
- í•„ë“œ ëˆ„ë½ ë¶ˆë§Œ 10ê±´+ â†’ CoverageCalculator + GapFiller
- ë¹„ì´ë ¥ì„œ ì—…ë¡œë“œ ë¹„ìœ¨ >5% â†’ DocumentClassifier
```

**ê¶Œì¥**: Beta í”¼ë“œë°± ìˆ˜ì§‘ í›„ ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì •

---

## 2. Phase 1 ì‹ ê·œ ì»´í¬ë„ŒíŠ¸ ìƒì„¸ ì„¤ê³„

### 2.1 DocumentClassifier (ResumeIntentGuard)

**ì—­í• **: ì´ë ¥ì„œ vs ë¹„ì´ë ¥ì„œ ë¶„ë¥˜

**íŒŒì¼ ìœ„ì¹˜**: `apps/worker/agents/document_classifier.py`

```python
from enum import Enum
from dataclasses import dataclass
from typing import Optional, List

class DocumentKind(str, Enum):
    RESUME = "resume"
    NON_RESUME = "non_resume"
    UNCERTAIN = "uncertain"

class NonResumeType(str, Enum):
    JOB_DESCRIPTION = "job_description"
    CERTIFICATE = "certificate"
    COMPANY_PROFILE = "company_profile"
    PORTFOLIO_ONLY = "portfolio_only"
    OTHER = "other"

@dataclass
class ClassificationResult:
    document_kind: DocumentKind
    confidence: float  # 0.0-1.0
    non_resume_type: Optional[NonResumeType]
    signals: List[str]  # ë¶„ë¥˜ ê·¼ê±°
    llm_used: bool  # LLM í˜¸ì¶œ ì—¬ë¶€

class DocumentClassifier:
    """
    2ë‹¨ê³„ ë¶„ë¥˜ê¸°:
    1. Rule-based (ë¹ ë¦„, ë¬´ë£Œ)
    2. LLM Fallback (ì •í™•í•¨, ë¹„ìš©)
    """

    # Rule-based ì‹ í˜¸
    RESUME_SIGNALS = [
        "ì´ë¦„", "ì—°ë½ì²˜", "ê²½ë ¥", "í•™ë ¥", "ê¸°ìˆ ",
        "name", "contact", "experience", "education", "skills"
    ]

    NON_RESUME_SIGNALS = {
        "job_description": ["ì±„ìš©", "ëª¨ì§‘", "ì§€ì›ìê²©", "ìš°ëŒ€ì‚¬í•­"],
        "certificate": ["ìˆ˜ë£Œì¦", "ìê²©ì¦", "certificate"],
        "company_profile": ["íšŒì‚¬ì†Œê°œ", "about us", "ì‚¬ì—…ì˜ì—­"],
    }

    async def classify(
        self,
        text: str,
        filename: str,
        confidence_threshold: float = 0.7
    ) -> ClassificationResult:
        """
        ë¶„ë¥˜ ìˆ˜í–‰

        Args:
            text: íŒŒì‹±ëœ í…ìŠ¤íŠ¸
            filename: íŒŒì¼ëª… (íŒíŠ¸ë¡œ í™œìš©)
            confidence_threshold: LLM fallback ê¸°ì¤€

        Returns:
            ClassificationResult
        """
        # Step 1: Rule-based ë¶„ë¥˜
        rule_result = self._classify_by_rules(text, filename)

        if rule_result.confidence >= confidence_threshold:
            return rule_result

        # Step 2: LLM Fallback (GPT-4o-mini)
        return await self._classify_by_llm(text, filename)

    def _classify_by_rules(self, text: str, filename: str) -> ClassificationResult:
        """ê·œì¹™ ê¸°ë°˜ ë¶„ë¥˜"""
        signals = []
        resume_score = 0

        # ì´ë ¥ì„œ ì‹ í˜¸ íƒì§€
        for signal in self.RESUME_SIGNALS:
            if signal in text.lower():
                signals.append(f"resume_signal:{signal}")
                resume_score += 1

        # ë¹„ì´ë ¥ì„œ ì‹ í˜¸ íƒì§€
        non_resume_type = None
        for nr_type, keywords in self.NON_RESUME_SIGNALS.items():
            if any(kw in text.lower() for kw in keywords):
                non_resume_type = NonResumeType(nr_type)
                signals.append(f"non_resume_signal:{nr_type}")
                resume_score -= 2

        # ì‹ ë¢°ë„ ê³„ì‚°
        confidence = min(0.9, resume_score * 0.15) if resume_score > 0 else 0.3

        return ClassificationResult(
            document_kind=DocumentKind.RESUME if resume_score > 2 else DocumentKind.UNCERTAIN,
            confidence=confidence,
            non_resume_type=non_resume_type,
            signals=signals,
            llm_used=False
        )

    async def _classify_by_llm(self, text: str, filename: str) -> ClassificationResult:
        """LLM ê¸°ë°˜ ë¶„ë¥˜ (GPT-4o-mini)"""
        # LLM í˜¸ì¶œ êµ¬í˜„
        pass
```

**íŒŒì´í”„ë¼ì¸ ìœ„ì¹˜**: RouterAgent â†’ Parser â†’ **DocumentClassifier** â†’ IdentityChecker

**LLM ë¹„ìš© ë¶„ì„**:

| ë°©ì‹ | ë¹„ìš©/ê±´ | ì •í™•ë„ | ì§€ì—° |
|------|---------|--------|------|
| Rule-based only | $0 | 80-85% | +0.1ì´ˆ |
| Rule + LLM fallback | ~$0.001 | 95%+ | +1-2ì´ˆ (fallback ì‹œ) |

**íŠ¸ë¦¬ê±° ì¡°ê±´**: ë¹„ì´ë ¥ì„œ ì—…ë¡œë“œ ë¹„ìœ¨ >5%

---

### 2.2 CoverageCalculator

**ì—­í• **: í•„ë“œ ì™„ì„±ë„ ì ìˆ˜ ì‚°ì¶œ + missing_reason ì¶”ì 

**íŒŒì¼ ìœ„ì¹˜**: `apps/worker/agents/coverage_calculator.py`

```python
from dataclasses import dataclass
from typing import Dict, List, Optional, Any
from enum import Enum

class MissingReason(str, Enum):
    NOT_FOUND_IN_SOURCE = "not_found_in_source"
    PARSER_ERROR = "parser_error"
    LLM_EXTRACTION_FAILED = "llm_extraction_failed"
    LOW_CONFIDENCE = "low_confidence"
    SCHEMA_MISMATCH = "schema_mismatch"
    TIMEOUT = "timeout"

class FieldPriority(str, Enum):
    CRITICAL = "critical"      # ê°€ì¤‘ì¹˜ 0.3
    IMPORTANT = "important"    # ê°€ì¤‘ì¹˜ 0.15
    OPTIONAL = "optional"      # ê°€ì¤‘ì¹˜ 0.05

@dataclass
class FieldCoverage:
    field_name: str
    has_value: bool
    has_evidence: bool
    confidence: float
    missing_reason: Optional[MissingReason]
    evidence_span: Optional[str]  # ì›ë¬¸ ìœ„ì¹˜ ì°¸ì¡°

@dataclass
class CoverageResult:
    coverage_score: float  # 0-100
    evidence_backed_ratio: float  # 0-1
    field_coverages: Dict[str, FieldCoverage]
    missing_fields: List[str]
    low_confidence_fields: List[str]
    gap_fill_candidates: List[str]  # GapFiller ëŒ€ìƒ

class CoverageCalculator:
    """
    í•„ë“œ ì™„ì„±ë„ ê³„ì‚°ê¸°

    LLM í˜¸ì¶œ: 0 (ìˆœìˆ˜ ê³„ì‚°)
    """

    # í•„ë“œ ê°€ì¤‘ì¹˜ ì •ì˜
    FIELD_WEIGHTS = {
        # Critical (30%)
        "name": (FieldPriority.CRITICAL, 0.08),
        "phone": (FieldPriority.CRITICAL, 0.08),
        "email": (FieldPriority.CRITICAL, 0.07),
        "careers": (FieldPriority.CRITICAL, 0.07),

        # Important (45%)
        "skills": (FieldPriority.IMPORTANT, 0.10),
        "educations": (FieldPriority.IMPORTANT, 0.08),
        "exp_years": (FieldPriority.IMPORTANT, 0.07),
        "current_company": (FieldPriority.IMPORTANT, 0.05),
        "current_position": (FieldPriority.IMPORTANT, 0.05),
        "summary": (FieldPriority.IMPORTANT, 0.05),
        "strengths": (FieldPriority.IMPORTANT, 0.05),

        # Optional (25%)
        "birth_year": (FieldPriority.OPTIONAL, 0.04),
        "gender": (FieldPriority.OPTIONAL, 0.03),
        "address": (FieldPriority.OPTIONAL, 0.03),
        "projects": (FieldPriority.OPTIONAL, 0.05),
        "certifications": (FieldPriority.OPTIONAL, 0.05),
        "links": (FieldPriority.OPTIONAL, 0.05),
    }

    GAP_FILL_THRESHOLD = 0.85  # ì´ ì´ìƒì´ë©´ GapFiller ìŠ¤í‚µ
    LOW_CONFIDENCE_THRESHOLD = 0.6

    def calculate(
        self,
        analyzed_data: Dict[str, Any],
        evidence_map: Dict[str, Any],
        original_text: str
    ) -> CoverageResult:
        """
        í•„ë“œ ì™„ì„±ë„ ê³„ì‚°

        Args:
            analyzed_data: AnalystAgent ì¶œë ¥
            evidence_map: í•„ë“œë³„ ì›ë¬¸ ê·¼ê±°
            original_text: íŒŒì‹±ëœ ì›ë¬¸

        Returns:
            CoverageResult
        """
        field_coverages = {}
        total_weight = 0
        achieved_weight = 0
        evidence_count = 0

        for field_name, (priority, weight) in self.FIELD_WEIGHTS.items():
            value = analyzed_data.get(field_name)
            evidence = evidence_map.get(field_name)
            confidence = analyzed_data.get("field_confidence", {}).get(field_name, 0.5)

            has_value = self._has_meaningful_value(value)
            has_evidence = evidence is not None and len(str(evidence)) > 0

            # Missing reason ê²°ì •
            missing_reason = None
            if not has_value:
                missing_reason = self._determine_missing_reason(
                    field_name, value, evidence, original_text
                )

            field_coverages[field_name] = FieldCoverage(
                field_name=field_name,
                has_value=has_value,
                has_evidence=has_evidence,
                confidence=confidence,
                missing_reason=missing_reason,
                evidence_span=evidence
            )

            total_weight += weight
            if has_value and confidence >= self.LOW_CONFIDENCE_THRESHOLD:
                achieved_weight += weight
            if has_evidence:
                evidence_count += 1

        # ì ìˆ˜ ê³„ì‚°
        coverage_score = (achieved_weight / total_weight) * 100 if total_weight > 0 else 0
        evidence_backed_ratio = evidence_count / len(self.FIELD_WEIGHTS)

        # GapFiller ëŒ€ìƒ ì‹ë³„
        missing_fields = [
            f for f, c in field_coverages.items()
            if not c.has_value
        ]
        low_confidence_fields = [
            f for f, c in field_coverages.items()
            if c.has_value and c.confidence < self.LOW_CONFIDENCE_THRESHOLD
        ]
        gap_fill_candidates = self._prioritize_gap_fill(
            missing_fields, low_confidence_fields
        )

        return CoverageResult(
            coverage_score=coverage_score,
            evidence_backed_ratio=evidence_backed_ratio,
            field_coverages=field_coverages,
            missing_fields=missing_fields,
            low_confidence_fields=low_confidence_fields,
            gap_fill_candidates=gap_fill_candidates
        )

    def _has_meaningful_value(self, value: Any) -> bool:
        """ì˜ë¯¸ ìˆëŠ” ê°’ì¸ì§€ í™•ì¸"""
        if value is None:
            return False
        if isinstance(value, str) and len(value.strip()) == 0:
            return False
        if isinstance(value, list) and len(value) == 0:
            return False
        return True

    def _determine_missing_reason(
        self,
        field_name: str,
        value: Any,
        evidence: Any,
        original_text: str
    ) -> MissingReason:
        """Missing reason ê²°ì •"""
        # ì›ë¬¸ì—ì„œ ê´€ë ¨ í‚¤ì›Œë“œ ê²€ìƒ‰
        field_keywords = {
            "phone": ["ì „í™”", "ì—°ë½ì²˜", "í•¸ë“œí°", "010", "phone"],
            "email": ["ì´ë©”ì¼", "email", "@"],
            "skills": ["ê¸°ìˆ ", "ìŠ¤í‚¬", "ì—­ëŸ‰", "skill"],
            "educations": ["í•™ë ¥", "í•™êµ", "ëŒ€í•™", "education"],
        }

        keywords = field_keywords.get(field_name, [])
        found_in_source = any(kw in original_text.lower() for kw in keywords)

        if not found_in_source:
            return MissingReason.NOT_FOUND_IN_SOURCE
        if evidence is not None:
            return MissingReason.LLM_EXTRACTION_FAILED
        return MissingReason.PARSER_ERROR

    def _prioritize_gap_fill(
        self,
        missing: List[str],
        low_confidence: List[str]
    ) -> List[str]:
        """GapFiller ìš°ì„ ìˆœìœ„ ê²°ì •"""
        # Critical > Important > Optional ìˆœì„œ
        priority_order = ["phone", "email", "skills", "careers", "name"]

        candidates = missing + low_confidence
        return [f for f in priority_order if f in candidates][:5]  # ìµœëŒ€ 5ê°œ
```

**íŒŒì´í”„ë¼ì¸ ìœ„ì¹˜**: AnalystAgent â†’ ValidationAgent â†’ **CoverageCalculator** â†’ GapFillerAgent

---

### 2.3 GapFillerAgent

**ì—­í• **: ë¹ˆ í•„ë“œ íƒ€ê²Ÿ ì¬ì¶”ì¶œ (ìµœëŒ€ 2íšŒ)

**íŒŒì¼ ìœ„ì¹˜**: `apps/worker/agents/gap_filler_agent.py`

```python
from dataclasses import dataclass
from typing import Dict, List, Any, Optional

@dataclass
class GapFillResult:
    success: bool
    filled_fields: Dict[str, Any]  # ì±„ì›Œì§„ í•„ë“œ
    still_missing: List[str]  # ì—¬ì „íˆ ë¹ˆ í•„ë“œ
    retries_used: int
    total_llm_calls: int

class GapFillerAgent:
    """
    ë¹ˆ í•„ë“œ íƒ€ê²Ÿ ì¬ì¶”ì¶œ

    ì „ëµ:
    1. CoverageCalculatorì—ì„œ ë°›ì€ gap_fill_candidatesë§Œ ì²˜ë¦¬
    2. í•„ë“œë³„ targeted prompt ì‚¬ìš©
    3. ìµœëŒ€ 2íšŒ ì¬ì‹œë„, 5ì´ˆ íƒ€ì„ì•„ì›ƒ
    4. coverage >= 85% ì´ë©´ ìŠ¤í‚µ
    """

    MAX_RETRIES = 2
    TIMEOUT_SECONDS = 5
    SKIP_THRESHOLD = 0.85  # 85% ì´ìƒì´ë©´ ìŠ¤í‚µ

    # í•„ë“œë³„ targeted prompt í…œí”Œë¦¿
    FIELD_PROMPTS = {
        "phone": """
Extract ONLY the phone number from this resume text.
Return in format: 010-XXXX-XXXX
If not found, return null.
""",
        "email": """
Extract ONLY the email address from this resume text.
If not found, return null.
""",
        "skills": """
Extract ONLY the technical skills and tools mentioned in this resume.
Return as a JSON array of strings.
If none found, return empty array.
""",
        "careers": """
Extract ONLY the work experience/career history from this resume.
For each position, extract: company, position, start_date, end_date.
Return as a JSON array.
If none found, return empty array.
""",
    }

    async def fill_gaps(
        self,
        gap_candidates: List[str],
        current_data: Dict[str, Any],
        original_text: str,
        coverage_score: float
    ) -> GapFillResult:
        """
        ë¹ˆ í•„ë“œ ì±„ìš°ê¸°

        Args:
            gap_candidates: CoverageCalculatorì—ì„œ ë°›ì€ ëŒ€ìƒ í•„ë“œ
            current_data: í˜„ì¬ê¹Œì§€ ë¶„ì„ëœ ë°ì´í„°
            original_text: ì›ë¬¸
            coverage_score: í˜„ì¬ coverage ì ìˆ˜

        Returns:
            GapFillResult
        """
        # Skip if coverage is high enough
        if coverage_score >= self.SKIP_THRESHOLD * 100:
            return GapFillResult(
                success=True,
                filled_fields={},
                still_missing=[],
                retries_used=0,
                total_llm_calls=0
            )

        filled = {}
        still_missing = []
        total_calls = 0

        for field in gap_candidates:
            if field not in self.FIELD_PROMPTS:
                still_missing.append(field)
                continue

            # Targeted extraction with retries
            result = await self._extract_field_with_retry(
                field, original_text
            )
            total_calls += result["calls"]

            if result["value"] is not None:
                filled[field] = result["value"]
            else:
                still_missing.append(field)

        return GapFillResult(
            success=len(filled) > 0,
            filled_fields=filled,
            still_missing=still_missing,
            retries_used=total_calls,
            total_llm_calls=total_calls
        )

    async def _extract_field_with_retry(
        self,
        field: str,
        text: str
    ) -> Dict[str, Any]:
        """ë‹¨ì¼ í•„ë“œ ì¬ì¶”ì¶œ (with retry)"""
        prompt = self.FIELD_PROMPTS[field]
        calls = 0

        for attempt in range(self.MAX_RETRIES):
            calls += 1
            try:
                result = await self._call_llm_with_timeout(
                    prompt, text, self.TIMEOUT_SECONDS
                )
                if result is not None:
                    return {"value": result, "calls": calls}
            except TimeoutError:
                continue

        return {"value": None, "calls": calls}

    async def _call_llm_with_timeout(
        self,
        prompt: str,
        text: str,
        timeout: int
    ) -> Optional[Any]:
        """íƒ€ì„ì•„ì›ƒì´ ìˆëŠ” LLM í˜¸ì¶œ"""
        # LLM Managerë¥¼ í†µí•œ í˜¸ì¶œ êµ¬í˜„
        pass
```

**íŒŒì´í”„ë¼ì¸ ìœ„ì¹˜**: CoverageCalculator â†’ **GapFillerAgent** â†’ PrivacyAgent

---

## 3. í†µí•© ì•„í‚¤í…ì²˜ ë³€ê²½

### 3.1 ìˆ˜ì •ëœ Pipeline Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PHASE 1 ENHANCED PIPELINE                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  STAGE 1: VALIDATION                                                     â”‚
â”‚  â”œâ”€ RouterAgent (Magic number, DRM, Size) â”€â”€â”€â”€â”€â–º Reject or Continue     â”‚
â”‚  â”œâ”€ File Parser (HWP/PDF/DOCX) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º raw_text                  â”‚
â”‚  â””â”€ [NEW] DocumentClassifier â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º document_kind             â”‚
â”‚           â”‚                                                              â”‚
â”‚           â”œâ”€ resume â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Continue                  â”‚
â”‚           â”œâ”€ non_resume â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Reject + Refund           â”‚
â”‚           â””â”€ uncertain â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Continue with warning     â”‚
â”‚                                                                          â”‚
â”‚  STAGE 2: PRE-SCREENING                                                  â”‚
â”‚  â””â”€ IdentityChecker (Multi-person detection) â”€â–º Reject or Continue      â”‚
â”‚                                                                          â”‚
â”‚  STAGE 3: AI ANALYSIS                                                    â”‚
â”‚  â”œâ”€ AnalystAgent (GPT-4o + Gemini Cross-Check)                          â”‚
â”‚  â”‚     â””â”€â–º analyzed_data + field_confidence + evidence_map              â”‚
â”‚  â”‚                                                                       â”‚
â”‚  â”œâ”€ ValidationAgent (Rule-based verification)                           â”‚
â”‚  â”‚     â””â”€â–º corrected_data + confidence_adjustments                      â”‚
â”‚  â”‚                                                                       â”‚
â”‚  â”œâ”€ [NEW] CoverageCalculator                                            â”‚
â”‚  â”‚     â””â”€â–º coverage_score + missing_fields + gap_fill_candidates        â”‚
â”‚  â”‚                                                                       â”‚
â”‚  â””â”€ [NEW] GapFillerAgent (if coverage < 85%)                            â”‚
â”‚        â””â”€â–º filled_fields (0-2 LLM calls per field)                      â”‚
â”‚                                                                          â”‚
â”‚  STAGE 4: PRIVACY & STORAGE                                              â”‚
â”‚  â”œâ”€ PrivacyAgent (AES-256-GCM encryption)                               â”‚
â”‚  â”œâ”€ EmbeddingService (text-embedding-3-small)                           â”‚
â”‚  â”œâ”€ DatabaseService (Supabase + pgvector)                               â”‚
â”‚  â””â”€ VisualAgent (Portfolio capture, optional)                           â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 Unified Resume Context Contract

ëª¨ë“  ì—ì´ì „íŠ¸ê°€ ê³µìœ í•´ì•¼ í•˜ëŠ” ì»¨í…ìŠ¤íŠ¸:

```json
{
  "resume_intent": true,
  "document_type": "resume",
  "resume_id": "uuid",
  "pipeline_id": "uuid",
  "raw_text": "...",
  "sections": ["profile", "career", "education", "skills", "projects"],
  "evidence_map": {
    "name": {"text": "í™ê¸¸ë™", "span": [0, 15], "page": 1},
    "phone": {"text": "010-1234-5678", "span": [20, 35], "page": 1}
  },
  "field_metadata": {
    "name": {"source": "analyst", "confidence": 0.95},
    "phone": {"source": "gap_filler", "confidence": 0.88}
  },
  "missing_policy": "allow_null_only_if_not_found_in_source"
}
```

**Rules**:
1. `document_type != resume` â†’ LLM-heavy ë‹¨ê³„ ì „ ì¤‘ë‹¨
2. ëª¨ë“  agent outputì— field-level evidence í¬í•¨
3. OrchestratorëŠ” `value + evidence` ë˜ëŠ” `missing_reason`ë§Œ ì €ì¥
4. GapFillerëŠ” ë™ì¼ `resume_id` ì»¨í…ìŠ¤íŠ¸ ìœ ì§€

### 3.3 PipelineOrchestrator ìˆ˜ì •

```python
# apps/worker/orchestrator/pipeline_orchestrator.py ìˆ˜ì • ì‚¬í•­

class PipelineOrchestrator:
    async def run(self, ...) -> OrchestratorResult:
        # ... ê¸°ì¡´ ì½”ë“œ ...

        # Stage 1.5: Document Classification (NEW)
        if self.feature_flags.use_document_classifier:
            classification = await self.document_classifier.classify(
                text=parsed_text,
                filename=filename
            )

            if classification.document_kind == DocumentKind.NON_RESUME:
                return self._create_rejection_result(
                    reason="non_resume",
                    non_resume_type=classification.non_resume_type
                )

            ctx.set_document_kind(classification)

        # ... ê¸°ì¡´ ë¶„ì„ ì½”ë“œ ...

        # Stage 3.5: Coverage Calculation (NEW)
        if self.feature_flags.use_coverage_calculator:
            coverage = self.coverage_calculator.calculate(
                analyzed_data=ctx.current_data.to_dict(),
                evidence_map=ctx.evidence_store.get_all(),
                original_text=parsed_text
            )

            ctx.set_coverage(coverage)

            # Stage 3.6: Gap Filling (NEW)
            if (self.feature_flags.use_gap_filler and
                coverage.coverage_score < 85):
                gap_result = await self.gap_filler.fill_gaps(
                    gap_candidates=coverage.gap_fill_candidates,
                    current_data=ctx.current_data.to_dict(),
                    original_text=parsed_text,
                    coverage_score=coverage.coverage_score
                )

                ctx.merge_filled_fields(gap_result.filled_fields)

        # ... ì´í›„ ì½”ë“œ ...
```

---

## 4. ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ë³€ê²½

### 4.1 candidates í…Œì´ë¸” í™•ì¥

```sql
-- Migration: add_phase1_fields.sql

-- 1. ENUM íƒ€ì… ìƒì„±
CREATE TYPE document_kind_enum AS ENUM ('resume', 'non_resume', 'uncertain');
CREATE TYPE missing_reason_enum AS ENUM (
  'not_found_in_source',
  'parser_error',
  'llm_extraction_failed',
  'low_confidence',
  'schema_mismatch',
  'timeout'
);

-- 2. ì»¬ëŸ¼ ì¶”ê°€
ALTER TABLE candidates
  ADD COLUMN IF NOT EXISTS document_kind document_kind_enum DEFAULT 'resume',
  ADD COLUMN IF NOT EXISTS doc_confidence DECIMAL(3,2),
  ADD COLUMN IF NOT EXISTS field_metadata JSONB DEFAULT '{}',
  ADD COLUMN IF NOT EXISTS coverage_score DECIMAL(5,2),
  ADD COLUMN IF NOT EXISTS evidence_backed_ratio DECIMAL(3,2);

-- 3. ì¸ë±ìŠ¤ ì¶”ê°€
CREATE INDEX IF NOT EXISTS idx_candidates_document_kind
  ON candidates(document_kind);
CREATE INDEX IF NOT EXISTS idx_candidates_coverage_score
  ON candidates(coverage_score);

-- 4. field_metadata JSONB êµ¬ì¡° ì˜ˆì‹œ
COMMENT ON COLUMN candidates.field_metadata IS '
{
  "name": {
    "source": "analyst",
    "confidence": 0.95,
    "evidence_span": [0, 15],
    "missing_reason": null
  },
  "phone": {
    "source": "gap_filler",
    "confidence": 0.88,
    "evidence_span": [20, 35],
    "missing_reason": null
  },
  "address": {
    "source": null,
    "confidence": null,
    "evidence_span": null,
    "missing_reason": "not_found_in_source"
  }
}';
```

### 4.2 processing_jobs í…Œì´ë¸” í™•ì¥

```sql
-- processing_jobsì— Phase 1 ë©”íƒ€ë°ì´í„° ì¶”ê°€
ALTER TABLE processing_jobs
  ADD COLUMN IF NOT EXISTS document_classification JSONB DEFAULT '{}',
  ADD COLUMN IF NOT EXISTS coverage_metrics JSONB DEFAULT '{}',
  ADD COLUMN IF NOT EXISTS gap_fill_attempts INT DEFAULT 0;
```

---

## 5. Feature Flags ì¶”ê°€

```python
# apps/worker/orchestrator/feature_flags.py

@dataclass
class FeatureFlags:
    # ê¸°ì¡´ í”Œë˜ê·¸
    debug_pipeline: bool = False
    use_llm_validation: bool = True
    use_hallucination_detection: bool = True
    use_evidence_tracking: bool = True

    # Phase 1 ì‹ ê·œ í”Œë˜ê·¸
    use_document_classifier: bool = False  # T4-4
    use_coverage_calculator: bool = False  # T4-3
    use_gap_filler: bool = False           # T4-3
    gap_filler_max_retries: int = 2
    gap_filler_timeout: int = 5
    coverage_threshold: float = 0.85
```

---

## 6. ë¦¬ìŠ¤í¬ ë° ë‹¨ì  ë¶„ì„

### 6.1 ê¸°ìˆ ì  ë¦¬ìŠ¤í¬

| ë¦¬ìŠ¤í¬ | ì˜í–¥ë„ | ì™„í™” ë°©ì•ˆ |
|--------|--------|----------|
| **LLM ë¹„ìš© ì¦ê°€** | MEDIUM | GapFiller: coverage >= 85% ì‹œ ìŠ¤í‚µ, ìµœëŒ€ 2íšŒ ì¬ì‹œë„ |
| **íŒŒì´í”„ë¼ì¸ ì§€ì—°** | LOW | DocumentClassifier: Rule-based ìš°ì„ , LLM fallbackì€ ~1ì´ˆ |
| **ë³µì¡ë„ ì¦ê°€** | MEDIUM | Feature flagë¡œ ì ì§„ì  í™œì„±í™”, ë¡¤ë°± ìš©ì´ |
| **ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜** | LOW | í˜¸í™˜ì„± ìœ ì§€ (ê¸°ì¡´ ì»¬ëŸ¼ ì˜í–¥ ì—†ìŒ) |

### 6.2 ë¹„ì¦ˆë‹ˆìŠ¤ ë¦¬ìŠ¤í¬

| ë¦¬ìŠ¤í¬ | ì˜í–¥ë„ | ì™„í™” ë°©ì•ˆ |
|--------|--------|----------|
| **ì˜¤ë¶„ë¥˜ë¡œ ì¸í•œ í¬ë ˆë”§ í™˜ë¶ˆ** | MEDIUM | DocumentClassifier confidence < 0.7 ì‹œ uncertain ì²˜ë¦¬, í†µê³¼ |
| **GapFiller ì‹¤íŒ¨ ì‹œ ì‚¬ìš©ì ê¸°ëŒ€ì¹˜** | LOW | coverage_scoreë¥¼ UIì— í‘œì‹œí•˜ì—¬ íˆ¬ëª…ì„± í™•ë³´ |
| **ë¹„ì´ë ¥ì„œ ì°¨ë‹¨ìœ¼ë¡œ ì¸í•œ ë¶ˆë§Œ** | LOW | í™˜ë¶ˆ + ëª…í™•í•œ ì‚¬ìœ  ì•ˆë‚´ |

### 6.3 êµ¬í˜„ ìš°ì„ ìˆœìœ„ ê¶Œê³ 

```
í˜„ì¬ ê¶Œì¥: êµ¬í˜„ ë³´ë¥˜ (TIER 4)

íŠ¸ë¦¬ê±° ì¡°ê±´:
1. í•„ë“œ ëˆ„ë½ ë¶ˆë§Œ 10ê±´+ â†’ CoverageCalculator + GapFiller êµ¬í˜„
2. ë¹„ì´ë ¥ì„œ ì—…ë¡œë“œ >5% â†’ DocumentClassifier êµ¬í˜„
3. Pro ìœ ì € 10ëª…+ â†’ 3-Way Cross-Check ê²€í† 

ê·¼ê±°:
- í˜„ì¬ 95% ì„±ê³µë¥ ë¡œ Beta ìš´ì˜ ê°€ëŠ¥
- 8-15ì´ˆ ì²˜ë¦¬ ì‹œê°„ì€ í—ˆìš© ë²”ìœ„
- í”¼ë“œë°± ì—†ì´ ê³¼ë„í•œ ìµœì í™”ëŠ” Over-engineering
```

---

## 7. êµ¬í˜„ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Phase 1A: DocumentClassifier

- [ ] `apps/worker/agents/document_classifier.py` ìƒì„±
- [ ] Rule-based ë¶„ë¥˜ ë¡œì§ êµ¬í˜„
- [ ] LLM fallback êµ¬í˜„ (GPT-4o-mini)
- [ ] `pipeline_orchestrator.py`ì— í†µí•©
- [ ] Feature flag ì¶”ê°€: `use_document_classifier`
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
- [ ] DB ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜

### Phase 1B: CoverageCalculator

- [ ] `apps/worker/agents/coverage_calculator.py` ìƒì„±
- [ ] í•„ë“œ ê°€ì¤‘ì¹˜ ì •ì˜
- [ ] Missing reason ë¡œì§ êµ¬í˜„
- [ ] `pipeline_orchestrator.py`ì— í†µí•©
- [ ] Feature flag ì¶”ê°€: `use_coverage_calculator`
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±

### Phase 1C: GapFillerAgent

- [ ] `apps/worker/agents/gap_filler_agent.py` ìƒì„±
- [ ] í•„ë“œë³„ targeted prompt ì •ì˜
- [ ] ì¬ì‹œë„ ë¡œì§ êµ¬í˜„
- [ ] `pipeline_orchestrator.py`ì— í†µí•©
- [ ] Feature flag ì¶”ê°€: `use_gap_filler`
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„±

### ê³µí†µ

- [ ] `CLAUDE.md` ì—…ë°ì´íŠ¸ (ìƒˆ ì—ì´ì „íŠ¸ ì¶”ê°€)
- [ ] `MULTI_AGENT_PIPELINE.md` ìƒíƒœ ì—…ë°ì´íŠ¸
- [ ] E2E í…ŒìŠ¤íŠ¸ ì¶”ê°€

---

## 8. ì˜ˆìƒ ê³µìˆ˜

| ì‘ì—… | ê³µìˆ˜ | ì˜ì¡´ì„± |
|------|------|--------|
| DocumentClassifier | 6h | ì—†ìŒ |
| CoverageCalculator | 4h | ì—†ìŒ |
| GapFillerAgent | 8h | CoverageCalculator |
| DB ë§ˆì´ê·¸ë ˆì´ì…˜ | 2h | ì—†ìŒ |
| í…ŒìŠ¤íŠ¸ ì‘ì„± | 6h | ì „ì²´ |
| í†µí•© ë° ê²€ì¦ | 4h | ì „ì²´ |
| **í•©ê³„** | **30h** | - |

---

## Changelog

| Version | Date | Changes |
|---------|------|---------|
| 1.0.0 | 2026-02-14 | Initial Phase 1 development requirements |
