# =====================================================
# RAI Worker - Staging Docker Compose
# =====================================================
# 사용법: docker-compose -f docker-compose.staging.yml up -d

version: "3.8"

services:
  # ─────────────────────────────────────────────────
  # RAI Worker Service
  # ─────────────────────────────────────────────────
  worker:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: rai-worker-staging
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      # 기본 설정
      - ENV=staging
      - DEBUG=false
      - LOG_LEVEL=INFO

      # Supabase (환경변수로 주입)
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_SERVICE_ROLE_KEY=${SUPABASE_SERVICE_ROLE_KEY}

      # Redis
      - REDIS_URL=redis://redis:6379

      # AI 모델
      - ANALYSIS_MODE=${ANALYSIS_MODE:-phase_1}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o}
      - OPENAI_MINI_MODEL=${OPENAI_MINI_MODEL:-gpt-4o-mini}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - GEMINI_MODEL=${GEMINI_MODEL:-gemini-3-pro-preview}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - ANTHROPIC_MODEL=${ANTHROPIC_MODEL:-claude-sonnet-4-20250514}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-text-embedding-3-small}
      - LLM_CONFIDENCE_THRESHOLD=${LLM_CONFIDENCE_THRESHOLD:-0.85}

      # 보안
      - ENCRYPTION_KEY=${ENCRYPTION_KEY}
      - WEBHOOK_SECRET=${WEBHOOK_SECRET}

      # CORS
      - ALLOWED_ORIGINS=${ALLOWED_ORIGINS:-https://rai-staging.vercel.app}

      # 파일 처리
      - MAX_FILE_SIZE_MB=${MAX_FILE_SIZE_MB:-50}
      - MAX_PAGE_COUNT=${MAX_PAGE_COUNT:-50}
      - MIN_TEXT_LENGTH=${MIN_TEXT_LENGTH:-100}

      # Webhook
      - WEBHOOK_URL=${WEBHOOK_URL}

      # 외부 API
      - HANCOM_API_KEY=${HANCOM_API_KEY:-}
      - SENTRY_DSN=${SENTRY_DSN:-}

      # Feature Flags - P0 최적화
      - USE_SPLIT_QUEUES=${USE_SPLIT_QUEUES:-true}
      - USE_CONDITIONAL_LLM=${USE_CONDITIONAL_LLM:-true}
      - USE_PARALLEL_LLM=${USE_PARALLEL_LLM:-true}

      # Feature Flags - 새 파이프라인
      - USE_NEW_PIPELINE=${USE_NEW_PIPELINE:-false}
      - USE_LLM_VALIDATION=${USE_LLM_VALIDATION:-false}
      - USE_AGENT_MESSAGING=${USE_AGENT_MESSAGING:-false}
      - USE_HALLUCINATION_DETECTION=${USE_HALLUCINATION_DETECTION:-true}
      - USE_EVIDENCE_TRACKING=${USE_EVIDENCE_TRACKING:-true}
      - NEW_PIPELINE_ROLLOUT_PERCENTAGE=${NEW_PIPELINE_ROLLOUT_PERCENTAGE:-0.0}
      - NEW_PIPELINE_USER_IDS=${NEW_PIPELINE_USER_IDS:-}
      - DEBUG_PIPELINE=${DEBUG_PIPELINE:-false}

    depends_on:
      redis:
        condition: service_healthy

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

    volumes:
      # 임시 파일 저장 (선택)
      - worker-tmp:/tmp

    networks:
      - rai-network

    deploy:
      resources:
        limits:
          cpus: "2"
          memory: 4G
        reservations:
          cpus: "1"
          memory: 2G

  # ─────────────────────────────────────────────────
  # Redis Service (Job Queue)
  # ─────────────────────────────────────────────────
  redis:
    image: redis:7-alpine
    container_name: rai-redis-staging
    restart: unless-stopped
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru

    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

    volumes:
      - redis-data:/data

    networks:
      - rai-network

    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 512M
        reservations:
          cpus: "0.25"
          memory: 256M

  # ─────────────────────────────────────────────────
  # RQ Worker (Background Job Processor)
  # ─────────────────────────────────────────────────
  rq-worker:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: rai-rq-worker-staging
    restart: unless-stopped
    command: python -m rq.cli worker parse_queue process_queue --url redis://redis:6379

    environment:
      # 동일한 환경 변수 설정
      - ENV=staging
      - DEBUG=false
      - LOG_LEVEL=INFO
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_SERVICE_ROLE_KEY=${SUPABASE_SERVICE_ROLE_KEY}
      - REDIS_URL=redis://redis:6379
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - ENCRYPTION_KEY=${ENCRYPTION_KEY}
      - WEBHOOK_SECRET=${WEBHOOK_SECRET}
      - USE_SPLIT_QUEUES=${USE_SPLIT_QUEUES:-true}
      - USE_CONDITIONAL_LLM=${USE_CONDITIONAL_LLM:-true}
      - USE_PARALLEL_LLM=${USE_PARALLEL_LLM:-true}
      - USE_NEW_PIPELINE=${USE_NEW_PIPELINE:-false}
      - NEW_PIPELINE_ROLLOUT_PERCENTAGE=${NEW_PIPELINE_ROLLOUT_PERCENTAGE:-0.0}

    depends_on:
      redis:
        condition: service_healthy

    networks:
      - rai-network

    deploy:
      resources:
        limits:
          cpus: "2"
          memory: 4G
        reservations:
          cpus: "1"
          memory: 2G

volumes:
  redis-data:
    driver: local
  worker-tmp:
    driver: local

networks:
  rai-network:
    driver: bridge
